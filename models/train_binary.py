# models/train_binary.py

from __future__ import annotations

import argparse
from pathlib import Path

import joblib
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier  # ğŸ”¥ ê³ ì„±ëŠ¥ íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸

from ids.io_utils import load_csv_with_meta
from ids.windowing import make_time_windows
from ids.features import window_to_feature_vector, label_for_window_binary


def build_binary_dataset(csv_path: str, window_sec: float) -> tuple[pd.DataFrame, np.ndarray]:
    """
    CSV â†’ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° â†’ feature vector + Binary Label (Normal/Attack)
    """
    df, col_info = load_csv_with_meta(csv_path)

    label_col = col_info["label"]
    if label_col is None:
        raise ValueError("Train CSVì— Label ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. config.LABEL_CANDIDATESë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    windows = make_time_windows(df, col_info, window_sec=window_sec)

    feat_list = []
    labels = []

    for w in windows:
        wdf = w.df
        y = label_for_window_binary(wdf, label_col)
        feat = window_to_feature_vector(wdf, col_info)

        feat_list.append(feat)
        labels.append(y)

    X = pd.DataFrame(feat_list)
    y_arr = np.array(labels, dtype=str)
    return X, y_arr


def main():
    parser = argparse.ArgumentParser(description="Train Binary Normal/Attack XGBoost model.")
    parser.add_argument(
        "--csv",
        type=str,
        required=True,
        help="Train CSV ê²½ë¡œ (ì˜ˆ: data/autohack2025_train.csv)",
    )
    parser.add_argument(
        "--window-sec",
        type=float,
        default=0.2,
        help="ìŠ¬ë¼ì´ë”© ìœˆë„ìš° í¬ê¸° (ì´ˆ)",
    )
    parser.add_argument(
        "--out",
        type=str,
        default="models_artifacts/binary_rf.pkl",  # ê²½ë¡œ/ì´ë¦„ ê·¸ëŒ€ë¡œ ìœ ì§€
        help="ì €ì¥í•  ëª¨ë¸ ê²½ë¡œ",
    )

    args = parser.parse_args()

    csv_path = args.csv
    window_sec = args.window_sec
    out_path = Path(args.out)

    print(f"[1] Loading train CSV: {csv_path}")
    X, y = build_binary_dataset(csv_path, window_sec)
    print(f"[1] Windows: {len(X)}, Features: {X.shape[1]}")

    # NaN ë°©ì§€
    X = X.fillna(0.0)

    # Train/val split
    X_train, X_val, y_train, y_val = train_test_split(
        X,
        y,
        test_size=0.2,
        random_state=42,
        stratify=y,
    )

    # í´ë˜ìŠ¤ ë¹„ìœ¨ â†’ Attack ë¹„ìœ¨ì— ë§ëŠ” scale_pos_weight ì„¤ì •
    n_normal = (y_train == "Normal").sum()
    n_attack = (y_train == "Attack").sum()
    if n_attack == 0:
        scale_pos_weight = 1.0
    else:
        scale_pos_weight = n_normal / max(1, n_attack)

    print("[2] Training XGBoost (Binary Normal vs Attack)...")
    clf = XGBClassifier(
        n_estimators=500,
        max_depth=6,
        learning_rate=0.05,
        subsample=0.9,
        colsample_bytree=0.9,
        objective="binary:logistic",
        tree_method="hist",
        eval_metric="logloss",
        scale_pos_weight=scale_pos_weight,
        n_jobs=-1,
        random_state=42,
    )
    clf.fit(X_train, y_train)

    print("[3] Validation report:")
    y_pred = clf.predict(X_val)
    print(classification_report(y_val, y_pred))

    # ëª¨ë¸ ì €ì¥ (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€: dictì— model/window_sec/feature_columns)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(
        {
            "model": clf,
            "window_sec": window_sec,
            "feature_columns": X.columns.tolist(),
        },
        out_path,
    )
    print(f"[âœ“] Saved binary model â†’ {out_path}")


if __name__ == "__main__":
    main()
